{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Copy of run_in_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorgemarpa/SNe_spec/blob/master/notebooks/run_in_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FnAfYlt5L3t",
        "colab_type": "text"
      },
      "source": [
        "# Running in Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNbxA7wB5L3v",
        "colab_type": "text"
      },
      "source": [
        "#### Getting Git Repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbL4O-AA5L3w",
        "colab_type": "code",
        "outputId": "9316b2fb-aba1-4872-bf7c-53dba6bbbb24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/jorgemarpa/SNe_spec"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SNe_spec'...\n",
            "remote: Enumerating objects: 144, done.\u001b[K\n",
            "remote: Counting objects: 100% (144/144), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 144 (delta 62), reused 110 (delta 37), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (144/144), 233.79 KiB | 213.00 KiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojhpIoPf5XEf",
        "colab_type": "code",
        "outputId": "5e9f0e0d-bc83-42d4-d5de-5662f5fa7d67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd SNe_spec/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SNe_spec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz3SU9Ih5L31",
        "colab_type": "text"
      },
      "source": [
        "#### Checking dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BO49-665L33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c173d3b2-440a-4676-8530-a19478eb93e7"
      },
      "source": [
        "#!pip3 install -r requirements.txt\n",
        "!pip3 install wandb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/bd/3909f10c9986d93c82c9ab8899f8002ed01f57ca597607a41955c403b86e/wandb-0.8.15-py2.py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 6.4MB/s \n",
            "\u001b[?25hCollecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/e3/5a55d48a29300160779f0a0d2776d17c1b762a2039b36de528b093b87d5b/watchdog-0.9.0.tar.gz (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.4MB/s \n",
            "\u001b[?25hCollecting gql>=0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/9c/2933b7791210e00f5c26a6243198cc03af9132c29cf85e4c22cb007f171e/gql-0.1.0.tar.gz\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/80/d7/2bfc9332e68d3e15ea97b9b1588b3899ad565120253d3fd71c8f7f13b4fe/shortuuid-0.5.0.tar.gz\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/2a/95ed0501cf5d8709490b1d3a3f9b5cf340da6c433f896bbe9ce08dbe6785/configparser-4.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.6.1)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/d7/89536db7654f2636549a10d85a918feefd9aa2cac0929dd6796c8e945e78/sentry_sdk-0.13.2-py2.py3-none-any.whl (91kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.21.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/8c/4543981439d23c4ff65b2e62dddd767ebc84a8e664a9b67e840d1e2730d3/GitPython-3.0.5-py3-none-any.whl (455kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 37.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (3.13)\n",
            "Collecting argh>=0.24.1\n",
            "  Downloading https://files.pythonhosted.org/packages/06/1c/e667a7126f0b84aaa1c56844337bf0ac12445d1beb9c8a6199a7314944bf/argh-0.26.2-py2.py3-none-any.whl\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting graphql-core>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/11/bc4a7eb440124271289d93e4d208bd07d94196038fabbe2a52435a07d3d3/graphql_core-2.2.1-py2.py3-none-any.whl (250kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from gql>=0.1.0->wandb) (2.2.1)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
            "Collecting gitdb2>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/6c/99296f89bad2ef85626e1df9f677acbee8885bb043ad82ad3ed4746d2325/gitdb2-2.0.6-py2.py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.1MB/s \n",
            "\u001b[?25hCollecting rx<3,>=1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/0f/5ef4ac78e2a538cc1b054eb86285fe0bf7a5dbaeaac2c584757c300515e2/Rx-1.6.1-py2.py3-none-any.whl (179kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 44.4MB/s \n",
            "\u001b[?25hCollecting smmap2>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: watchdog, gql, shortuuid, subprocess32, pathtools\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.9.0-cp36-none-any.whl size=73652 sha256=a636c5e648c1f2a24e2e0fc161fc2ff9c0ade0399f92e844104d9ca09d23fcf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/1d/d0/04cfe495619be2095eb8d89a31c42adb4e42b76495bc8f784c\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.1.0-cp36-none-any.whl size=5541 sha256=8ef63773d77cc6cf91b6a7c963f02937ecbe1def5d4131b52e6d5647a29790f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/8d/65/a3247f500d675d80a01e4d2f0ee44fe99f1faef575bc2a1664\n",
            "  Building wheel for shortuuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shortuuid: filename=shortuuid-0.5.0-cp36-none-any.whl size=5499 sha256=253b359740ca52afc2406f6824c68af637f4ae843be1b219bd939f237008ecd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/eb/fd/69e5177f67b505e44acbd1aedfbe44b91768ee0c4cd5636576\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=8d258a47ad4594bc50e3c641f4ebf9f828c667b21317635288e5ed4e98413335\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8786 sha256=dc6320a1999da27b2db393f25af1b6829e62f905e5ae170003628f9b1e401820\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built watchdog gql shortuuid subprocess32 pathtools\n",
            "Installing collected packages: argh, pathtools, watchdog, rx, graphql-core, gql, shortuuid, configparser, sentry-sdk, docker-pycreds, smmap2, gitdb2, GitPython, subprocess32, wandb\n",
            "Successfully installed GitPython-3.0.5 argh-0.26.2 configparser-4.0.2 docker-pycreds-0.4.0 gitdb2-2.0.6 gql-0.1.0 graphql-core-2.2.1 pathtools-0.1.2 rx-1.6.1 sentry-sdk-0.13.2 shortuuid-0.5.0 smmap2-2.0.5 subprocess32-3.5.4 wandb-0.8.15 watchdog-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KePtc26O7tIA",
        "colab_type": "code",
        "outputId": "ca44e637-4cd1-46e9-d2cc-aa705e48849d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: 36a12fb8d5c24a03f4a43f419d30c6c235e42a16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TU8sEzg5L36",
        "colab_type": "text"
      },
      "source": [
        "#### Downloading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT5ushCd5L38",
        "colab_type": "code",
        "outputId": "6c51bc53-3215-4706-8d77-0f72d7dbf9f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "main_path = '/content/drive/My Drive/data_for_SNe_spec'\n",
        "print(main_path)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/data_for_SNe_spec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQu52ESk5L3_",
        "colab_type": "text"
      },
      "source": [
        "## Running main program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3HiFf4L5L4A",
        "colab_type": "code",
        "outputId": "9cf9db41-02bc-4fa6-eba8-b6ba56666b20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "run main.py --help"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: main.py [-h] [--dry-run] [--run-name RUN_NAME] [--machine MACHINE]\n",
            "               [--mode MODE] [--data DATA] [--optim OPTIM] [--lr LR]\n",
            "               [--lr-sch LR_SCH] [--early-stop [EARLY_STOP]]\n",
            "               [--batch-size BATCH_SIZE] [--epochs NUM_EPOCHS] [--arch ARCH]\n",
            "               [--hidden-units H_UNITS] [--rnn-layers RNN_LAYERS]\n",
            "               [--dropout DROPOUT] [--rnn-bidir [RNN_BIDIR]]\n",
            "               [--kernel-size KERNEL_SIZE] [--comment COMMENT]\n",
            "\n",
            "Conv/RNN model to classifySNe Spectra into a Phase/delta-m_15 grid\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --dry-run             Load data and initialize models [False]\n",
            "  --run-name RUN_NAME   Name of the run\n",
            "  --machine MACHINE     Where is running ([local], colab, exalearn)\n",
            "  --mode MODE           Whether to do classification or regression ([clas],\n",
            "                        regr)\n",
            "  --data DATA           Which data use ([spec])\n",
            "  --optim OPTIM         Optimizer ([adam],sdg)\n",
            "  --lr LR               learning rate [1e-3]\n",
            "  --lr-sch LR_SCH       learning rate shceduler ([None], step, exp, cosine,\n",
            "                        plateau)\n",
            "  --early-stop [EARLY_STOP]\n",
            "                        Early stopping, [True]\n",
            "  --batch-size BATCH_SIZE\n",
            "                        batch size [64]\n",
            "  --epochs NUM_EPOCHS   total number of training epochs [150]\n",
            "  --arch ARCH           architecture for Enc & Dec ([lstm],gru,rnn,conv)\n",
            "  --hidden-units H_UNITS\n",
            "                        number of hidden units [32]\n",
            "  --rnn-layers RNN_LAYERS\n",
            "                        number of layers for rnn [5]\n",
            "  --dropout DROPOUT     dropout for rnn/conv layers [0.2]\n",
            "  --rnn-bidir [RNN_BIDIR]\n",
            "                        Bidirectional RNN [False]\n",
            "  --kernel-size KERNEL_SIZE\n",
            "                        kernel size for conv, use odd ints [5]\n",
            "  --comment COMMENT     extra comments\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I5U3sCM5L4D",
        "colab_type": "code",
        "outputId": "42c46123-e4d5-4145-bb73-dd224da18471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "run main.py --machine colab --lr 5e-3 --batch-size 256 --arch gru \\\n",
        "            --hidden-units 16 --rnn-layers 1 --run-name testing_many-to-one \\\n",
        "            --early-stop F --data spec-111519-1696"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/deep_sne/SNe_Spec_clas\" target=\"_blank\">https://app.wandb.ai/deep_sne/SNe_Spec_clas</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/deep_sne/SNe_Spec_clas/runs/6227wisv\" target=\"_blank\">https://app.wandb.ai/deep_sne/SNe_Spec_clas/runs/6227wisv</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "        dry_run\t: False\n",
            "       run_name\t: testing_many-to-one\n",
            "        machine\t: colab\n",
            "           mode\t: clas\n",
            "           data\t: spec-111519-1696\n",
            "          optim\t: adam\n",
            "             lr\t: 0.005\n",
            "         lr_sch\t: None\n",
            "     early_stop\t: False\n",
            "     batch_size\t: 256\n",
            "     num_epochs\t: 150\n",
            "           arch\t: gru\n",
            "        h_units\t: 16\n",
            "     rnn_layers\t: 1\n",
            "        dropout\t: 0.3\n",
            "      rnn_bidir\t: False\n",
            "    kernel_size\t: 3\n",
            "        comment\t: \n",
            "\n",
            "Training lenght  :  12800\n",
            "Validation lenght:  3328\n",
            "Summary:\n",
            "RecNN(\n",
            "  (rnn): GRU(1, 16, batch_first=True, dropout=0.3)\n",
            "  (linear): Linear(in_features=16, out_features=18, bias=True)\n",
            ")\n",
            "\n",
            "\n",
            "Num of trainable params:  1218\n",
            "\n",
            "\n",
            "Optimizer    : Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.005\n",
            "    weight_decay: 0\n",
            ")\n",
            "LR Scheduler : NoneType\n",
            "\n",
            "\n",
            "########################################\n",
            "########  Running in cuda  #############\n",
            "########################################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Is model in cuda?  True\n",
            "########################################\n",
            "\n",
            "Epoch 1\n",
            "Training iteration 1, global step 1\n",
            "Loss: 3.0216\n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** VALIDATION ***\n",
            "Loss: 2.1829\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 0.20 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 2\n",
            "Training iteration 1, global step 51\n",
            "Loss: 2.2110\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1771\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 0.40 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 3\n",
            "Training iteration 1, global step 101\n",
            "Loss: 2.2943\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.2257\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 0.60 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 4\n",
            "Training iteration 1, global step 151\n",
            "Loss: 2.2251\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.0802\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 0.82 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 5\n",
            "Training iteration 1, global step 201\n",
            "Loss: 2.1731\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1579\n",
            "----------------------------------------\n",
            "Time per epoch: 10 s\n",
            "Elapsed time  : 1.00 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 6\n",
            "Training iteration 1, global step 251\n",
            "Loss: 2.2187\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.2580\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 1.20 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 7\n",
            "Training iteration 1, global step 301\n",
            "Loss: 2.2352\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1462\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 1.40 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 8\n",
            "Training iteration 1, global step 351\n",
            "Loss: 2.1974\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.3117\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 1.60 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 9\n",
            "Training iteration 1, global step 401\n",
            "Loss: 2.3228\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.2257\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 1.82 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 10\n",
            "Training iteration 1, global step 451\n",
            "Loss: 2.2655\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.2702\n",
            "----------------------------------------\n",
            "Time per epoch: 10 s\n",
            "Elapsed time  : 1.98 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 11\n",
            "Training iteration 1, global step 501\n",
            "Loss: 2.2704\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.0980\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 2.18 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 12\n",
            "Training iteration 1, global step 551\n",
            "Loss: 2.2439\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1715\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 2.40 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 13\n",
            "Training iteration 1, global step 601\n",
            "Loss: 2.1853\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.2207\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 2.60 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 14\n",
            "Training iteration 1, global step 651\n",
            "Loss: 2.3457\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.4300\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 2.80 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 15\n",
            "Training iteration 1, global step 701\n",
            "Loss: 2.2047\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.5086\n",
            "----------------------------------------\n",
            "Time per epoch: 10 s\n",
            "Elapsed time  : 2.98 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 16\n",
            "Training iteration 1, global step 751\n",
            "Loss: 2.1855\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.3856\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 3.18 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 17\n",
            "Training iteration 1, global step 801\n",
            "Loss: 2.2521\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.2079\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 3.38 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 18\n",
            "Training iteration 1, global step 851\n",
            "Loss: 2.3907\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.3159\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 3.60 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 19\n",
            "Training iteration 1, global step 901\n",
            "Loss: 2.2966\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.4114\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 3.80 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 20\n",
            "Training iteration 1, global step 951\n",
            "Loss: 2.2782\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1874\n",
            "----------------------------------------\n",
            "Time per epoch: 10 s\n",
            "Elapsed time  : 3.98 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 21\n",
            "Training iteration 1, global step 1001\n",
            "Loss: 2.2899\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.2616\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 4.18 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 22\n",
            "Training iteration 1, global step 1051\n",
            "Loss: 2.2468\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1824\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 4.38 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 23\n",
            "Training iteration 1, global step 1101\n",
            "Loss: 2.2855\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1631\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 4.58 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 24\n",
            "Training iteration 1, global step 1151\n",
            "Loss: 2.1855\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1819\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 4.80 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 25\n",
            "Training iteration 1, global step 1201\n",
            "Loss: 2.1380\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.2635\n",
            "----------------------------------------\n",
            "Time per epoch: 10 s\n",
            "Elapsed time  : 4.97 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 26\n",
            "Training iteration 1, global step 1251\n",
            "Loss: 2.2355\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.2124\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 5.18 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 27\n",
            "Training iteration 1, global step 1301\n",
            "Loss: 2.1942\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.2920\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 5.38 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 28\n",
            "Training iteration 1, global step 1351\n",
            "Loss: 2.2795\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1182\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 5.58 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 29\n",
            "Training iteration 1, global step 1401\n",
            "Loss: 2.2033\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1489\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 5.80 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 30\n",
            "Training iteration 1, global step 1451\n",
            "Loss: 2.2840\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1572\n",
            "----------------------------------------\n",
            "Time per epoch: 10 s\n",
            "Elapsed time  : 5.97 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 31\n",
            "Training iteration 1, global step 1501\n",
            "Loss: 2.3302\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1449\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 6.17 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 32\n",
            "Training iteration 1, global step 1551\n",
            "Loss: 2.2230\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1567\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 6.38 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 33\n",
            "Training iteration 1, global step 1601\n",
            "Loss: 2.3136\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1997\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 6.58 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 34\n",
            "Training iteration 1, global step 1651\n",
            "Loss: 2.1898\n",
            "----------------------------------------\n",
            "*** VALIDATION ***\n",
            "Loss: 2.1733\n",
            "----------------------------------------\n",
            "Time per epoch: 12 s\n",
            "Elapsed time  : 6.78 m\n",
            "########################################\n",
            "########################################\n",
            "\n",
            "Epoch 35\n",
            "Training iteration 1, global step 1701\n",
            "Loss: 2.3058\n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3AAq5dXBZ_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}